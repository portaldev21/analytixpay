# üöÄ Plano de Melhorias - AnalytiXPay

> An√°lise completa e roadmap de melhorias para o projeto AnalytiXPay
> Data: 2025-10-24

---

## üìä Resumo Executivo

Este documento apresenta um plano detalhado de melhorias para o projeto AnalytiXPay, organizado por prioridade e complexidade de implementa√ß√£o.

**Estat√≠sticas da An√°lise:**
- ‚úÖ Pontos fortes identificados: 6
- üîß Melhorias propostas: 15
- ‚è±Ô∏è Tempo total estimado: 4-6 semanas
- üéØ Impacto esperado: +40% performance, +60% manutenibilidade

---

## üéØ Prioriza√ß√£o

| Prioridade | Descri√ß√£o | Tempo | Itens |
|------------|-----------|-------|-------|
| **P0** | Cr√≠tico - Seguran√ßa/Performance | 1-2 dias | 3 |
| **P1** | Alto - Quick Wins | 2-3 dias | 5 |
| **P2** | M√©dio - Melhorias importantes | 1 semana | 4 |
| **P3** | Baixo - Otimiza√ß√µes | 2 semanas | 2 |
| **P4** | Nice to have - Futuro | 1-2 semanas | 1 |

---

## üî• P0 - Cr√≠tico (1-2 dias)

### 1. Valida√ß√£o de Vari√°veis de Ambiente

**Problema:** Valida√ß√£o de env vars apenas em runtime, falhas silenciosas

**Arquivo:** Criar `src/lib/env.ts`

**Solu√ß√£o:**

```typescript
import { z } from 'zod'

const envSchema = z.object({
  // Supabase (obrigat√≥rios)
  NEXT_PUBLIC_SUPABASE_URL: z.string().url('URL do Supabase inv√°lida'),
  NEXT_PUBLIC_SUPABASE_ANON_KEY: z.string().min(1, 'Anon key √© obrigat√≥ria'),
  SUPABASE_SERVICE_ROLE_KEY: z.string().optional(),

  // App
  NEXT_PUBLIC_APP_URL: z.string().url().default('http://localhost:3000'),

  // OpenAI (opcional)
  OPENAI_API_KEY: z.string().optional(),

  // Node
  NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),
})

export type Env = z.infer<typeof envSchema>

function validateEnv(): Env {
  try {
    return envSchema.parse(process.env)
  } catch (error) {
    console.error('‚ùå Erro na valida√ß√£o de vari√°veis de ambiente:')
    console.error(error)
    throw new Error('Vari√°veis de ambiente inv√°lidas')
  }
}

export const env = validateEnv()

// Usage: import { env } from '@/lib/env'
```

**Atualizar em:** `src/lib/supabase/server.ts`, `src/lib/supabase/client.ts`, `src/lib/pdf/ai-parser.ts`

```typescript
// Antes
process.env.NEXT_PUBLIC_SUPABASE_URL!

// Depois
import { env } from '@/lib/env'
env.NEXT_PUBLIC_SUPABASE_URL
```

**Impacto:**
- ‚úÖ Erros detectados no build (n√£o em runtime)
- ‚úÖ Type-safe environment variables
- ‚úÖ Documenta√ß√£o autom√°tica de vars necess√°rias

**Tempo:** 1-2 horas

---

### 2. Rate Limiting para Upload de Faturas

**Problema:** Vulner√°vel a abuse (upload massivo), sem prote√ß√£o

**Arquivo:** Criar `src/lib/rate-limit.ts`

**Solu√ß√£o:**

```typescript
import { LRUCache } from 'lru-cache'

type RateLimitOptions = {
  interval: number // ms
  uniqueTokenPerInterval: number
}

export function rateLimit(options: RateLimitOptions) {
  const tokenCache = new LRUCache({
    max: options.uniqueTokenPerInterval || 500,
    ttl: options.interval || 60000,
  })

  return {
    check: (limit: number, token: string) =>
      new Promise<void>((resolve, reject) => {
        const tokenCount = (tokenCache.get(token) as number[]) || [0]
        if (tokenCount[0] === 0) {
          tokenCache.set(token, tokenCount)
        }
        tokenCount[0] += 1

        const currentUsage = tokenCount[0]
        const isRateLimited = currentUsage >= limit

        return isRateLimited ? reject() : resolve()
      }),
  }
}

// Limiter para uploads (5 uploads por 10 minutos)
export const uploadLimiter = rateLimit({
  interval: 10 * 60 * 1000, // 10 minutos
  uniqueTokenPerInterval: 500,
})
```

**Usar em:** `src/actions/invoice.actions.ts`

```typescript
export async function uploadInvoice(formData: FormData): Promise<TApiResponse<...>> {
  try {
    const user = await getCurrentUser()
    if (!user) {
      return { data: null, error: 'Usu√°rio n√£o autenticado', success: false }
    }

    // Rate limiting
    try {
      await uploadLimiter.check(5, user.id) // 5 uploads por 10min
    } catch {
      return {
        data: null,
        error: 'Limite de uploads excedido. Aguarde alguns minutos.',
        success: false
      }
    }

    // ... resto do c√≥digo
  }
}
```

**Depend√™ncia:** `npm install lru-cache`

**Impacto:**
- üîí Prote√ß√£o contra abuse
- üí∞ Redu√ß√£o de custos OpenAI
- ‚ö° Melhor controle de recursos

**Tempo:** 2-3 horas

---

### 3. Logging Estruturado

**Problema:** `console.log()` espalhado, sem contexto, dif√≠cil debug em produ√ß√£o

**Arquivo:** Criar `src/lib/logger.ts`

**Solu√ß√£o:**

```typescript
import { env } from './env'

type LogLevel = 'debug' | 'info' | 'warn' | 'error'

interface LogContext {
  userId?: string
  accountId?: string
  action?: string
  duration?: number
  [key: string]: any
}

class Logger {
  private isDev = env.NODE_ENV === 'development'

  private log(level: LogLevel, message: string, context?: LogContext) {
    const timestamp = new Date().toISOString()
    const logData = {
      timestamp,
      level,
      message,
      ...context,
    }

    // Em produ√ß√£o, enviar para servi√ßo de logging (Sentry, Datadog, etc)
    if (!this.isDev) {
      // TODO: Integrar com Sentry
      // Sentry.captureMessage(message, { level, extra: context })
    }

    // Console sempre (formatado)
    const emoji = {
      debug: 'üîç',
      info: '‚ÑπÔ∏è',
      warn: '‚ö†Ô∏è',
      error: '‚ùå',
    }[level]

    console[level === 'debug' ? 'log' : level](
      `${emoji} [${level.toUpperCase()}] ${message}`,
      this.isDev ? context : ''
    )
  }

  debug(message: string, context?: LogContext) {
    if (this.isDev) this.log('debug', message, context)
  }

  info(message: string, context?: LogContext) {
    this.log('info', message, context)
  }

  warn(message: string, context?: LogContext) {
    this.log('warn', message, context)
  }

  error(message: string, error?: Error, context?: LogContext) {
    this.log('error', message, {
      ...context,
      error: error?.message,
      stack: error?.stack,
    })
  }
}

export const logger = new Logger()
```

**Usar em todas as Server Actions:**

```typescript
// Antes
console.log('Attempting AI-based parsing...')
console.error('Error parsing PDF:', error)

// Depois
import { logger } from '@/lib/logger'

logger.info('Starting AI-based PDF parsing', {
  accountId,
  fileName: file.name
})

logger.error('PDF parsing failed', error, {
  accountId,
  fileName: file.name
})
```

**Impacto:**
- üîç Debug facilitado
- üìä M√©tricas estruturadas
- üö® Alertas em produ√ß√£o

**Tempo:** 3-4 horas

---

## ‚ö° P1 - Quick Wins (2-3 dias)

### 4. Helpers de Valida√ß√£o de Acesso

**Problema:** C√≥digo duplicado para valida√ß√£o de ownership em m√∫ltiplos actions

**Arquivo:** Atualizar `src/lib/supabase/server.ts`

**Solu√ß√£o:**

```typescript
/**
 * Require user to be account owner (throws if not)
 */
export async function requireAccountOwnership(accountId: string) {
  const supabase = await createClient()
  const user = await getCurrentUser()

  if (!user) {
    throw new Error('Usu√°rio n√£o autenticado')
  }

  const { data: account, error } = await supabase
    .from('accounts')
    .select('owner_id')
    .eq('id', accountId)
    .single()

  if (error || !account) {
    throw new Error('Conta n√£o encontrada')
  }

  if (account.owner_id !== user.id) {
    throw new Error('Apenas o dono da conta pode realizar esta a√ß√£o')
  }

  return { user, account, supabase }
}

/**
 * Require user to have access to account (throws if not)
 */
export async function requireAccountAccess(accountId: string) {
  const supabase = await createClient()
  const user = await getCurrentUser()

  if (!user) {
    throw new Error('Usu√°rio n√£o autenticado')
  }

  const hasAccess = await hasAccessToAccount(accountId)
  if (!hasAccess) {
    throw new Error('Acesso negado a esta conta')
  }

  return { user, supabase }
}
```

**Refatorar:** `src/actions/invoice.actions.ts`, `src/actions/account.actions.ts`

```typescript
// Antes (invoice.actions.ts - deleteInvoice)
const user = await getCurrentUser()
if (!user) {
  return { data: null, error: 'Usu√°rio n√£o autenticado', success: false }
}

const { data: account } = await supabase
  .from('accounts')
  .select('owner_id')
  .eq('id', accountId)
  .single()

if (!account || account.owner_id !== user.id) {
  return { data: null, error: 'Apenas o dono...', success: false }
}

// Depois
try {
  const { user, supabase } = await requireAccountOwnership(accountId)
  // ... resto do c√≥digo
} catch (error) {
  return {
    data: null,
    error: error instanceof Error ? error.message : 'Erro desconhecido',
    success: false
  }
}
```

**Impacto:**
- üìâ -50% c√≥digo duplicado
- üêõ Menos bugs de valida√ß√£o
- üßπ C√≥digo mais limpo

**Tempo:** 2-3 horas

---

### 5. Otimiza√ß√£o de Query N+1 (Invoice Summary)

**Problema:** Loop com queries individuais em `getInvoicesSummary`

**Arquivo:** `src/actions/invoice.actions.ts`

**Solu√ß√£o:**

```typescript
/**
 * Get invoices summary for dashboard (OPTIMIZED)
 */
export async function getInvoicesSummary(accountId: string): Promise<TApiResponse<{
  invoiceId: string
  period: string
  cardLastDigits: string | null
  totalAmount: number
  transactionCount: number
}[]>> {
  try {
    const supabase = await createClient()

    if (!(await hasAccessToAccount(accountId))) {
      return { data: null, error: 'Acesso negado', success: false }
    }

    // Single query with JOIN and aggregation
    const { data, error } = await supabase
      .rpc('get_invoices_summary', { p_account_id: accountId })

    if (error) {
      logger.error('Failed to get invoices summary', error, { accountId })
      return { data: null, error: error.message, success: false }
    }

    return { data: data || [], error: null, success: true }
  } catch (error) {
    logger.error('Unexpected error in getInvoicesSummary', error, { accountId })
    return {
      data: null,
      error: error instanceof Error ? error.message : 'Erro ao buscar resumo de faturas',
      success: false,
    }
  }
}
```

**Criar fun√ß√£o no Supabase SQL:**

```sql
-- db/functions/get_invoices_summary.sql
CREATE OR REPLACE FUNCTION get_invoices_summary(p_account_id uuid)
RETURNS TABLE (
  invoice_id uuid,
  period text,
  card_last_digits text,
  total_amount numeric,
  transaction_count bigint
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    i.id as invoice_id,
    COALESCE(i.period, 'Sem per√≠odo') as period,
    i.card_last_digits,
    COALESCE(i.total_amount, 0) as total_amount,
    COUNT(t.id) as transaction_count
  FROM invoices i
  LEFT JOIN transactions t ON t.invoice_id = i.id
  WHERE i.account_id = p_account_id
  GROUP BY i.id
  ORDER BY i.created_at DESC;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**Impacto:**
- ‚ö° 10x mais r√°pido (1 query ao inv√©s de N)
- üíæ Menos mem√≥ria
- üìä Escal√°vel

**Tempo:** 2-3 horas

---

### 6. Centraliza√ß√£o de C√°lculos de Stats

**Problema:** L√≥gica duplicada em `getTransactionStats` e `getDashboardStats`

**Arquivo:** Criar `src/lib/analytics/stats.ts`

**Solu√ß√£o:**

```typescript
import type { TTransaction } from '@/db/types'

export interface TransactionStats {
  totalSpent: number
  averageTransaction: number
  transactionCount: number
  categoryBreakdown: {
    category: string
    total: number
    count: number
    percentage: number
  }[]
}

export interface MonthlyComparison {
  currentMonth: number
  lastMonth: number
  percentageChange: number
}

/**
 * Calculate transaction statistics
 */
export function calculateTransactionStats(
  transactions: TTransaction[]
): TransactionStats {
  const totalSpent = transactions.reduce((sum, t) => sum + Number(t.amount), 0)
  const averageTransaction = transactions.length > 0
    ? totalSpent / transactions.length
    : 0

  // Category breakdown
  const categoryMap = new Map<string, { total: number; count: number }>()

  for (const transaction of transactions) {
    const existing = categoryMap.get(transaction.category) || { total: 0, count: 0 }
    categoryMap.set(transaction.category, {
      total: existing.total + Number(transaction.amount),
      count: existing.count + 1,
    })
  }

  const categoryBreakdown = Array.from(categoryMap.entries())
    .map(([category, stats]) => ({
      category,
      total: stats.total,
      count: stats.count,
      percentage: totalSpent > 0 ? (stats.total / totalSpent) * 100 : 0,
    }))
    .sort((a, b) => b.total - a.total) // Sort by total desc

  return {
    totalSpent,
    averageTransaction,
    transactionCount: transactions.length,
    categoryBreakdown,
  }
}

/**
 * Calculate monthly comparison
 */
export function calculateMonthlyComparison(
  transactions: TTransaction[]
): MonthlyComparison {
  const now = new Date()
  const currentMonth = now.getMonth()
  const currentYear = now.getFullYear()

  const currentMonthTransactions = transactions.filter((t) => {
    const date = new Date(t.date)
    return date.getMonth() === currentMonth && date.getFullYear() === currentYear
  })

  const lastMonth = currentMonth === 0 ? 11 : currentMonth - 1
  const lastMonthYear = currentMonth === 0 ? currentYear - 1 : currentYear

  const lastMonthTransactions = transactions.filter((t) => {
    const date = new Date(t.date)
    return date.getMonth() === lastMonth && date.getFullYear() === lastMonthYear
  })

  const currentMonthTotal = currentMonthTransactions.reduce(
    (sum, t) => sum + Number(t.amount),
    0
  )
  const lastMonthTotal = lastMonthTransactions.reduce(
    (sum, t) => sum + Number(t.amount),
    0
  )

  const percentageChange =
    lastMonthTotal > 0
      ? ((currentMonthTotal - lastMonthTotal) / lastMonthTotal) * 100
      : 0

  return {
    currentMonth: currentMonthTotal,
    lastMonth: lastMonthTotal,
    percentageChange,
  }
}
```

**Refatorar actions:**

```typescript
// src/actions/transaction.actions.ts
import { calculateTransactionStats, calculateMonthlyComparison } from '@/lib/analytics/stats'

export async function getDashboardStats(accountId: string): Promise<TApiResponse<TDashboardStats>> {
  // ... buscar transactions

  const stats = calculateTransactionStats(transactionList)
  const monthlyComparison = calculateMonthlyComparison(transactionList)

  return {
    data: {
      ...stats,
      largestTransaction: /* ... */,
      monthlyComparison,
    },
    error: null,
    success: true,
  }
}
```

**Impacto:**
- üß™ Test√°vel isoladamente
- üîÑ Reutiliz√°vel
- üêõ Consist√™ncia garantida

**Tempo:** 2-3 horas

---

### 7. Pagina√ß√£o em Listagens

**Problema:** Queries sem limite, podem retornar milhares de registros

**Arquivo:** `src/actions/transaction.actions.ts`

**Solu√ß√£o:**

```typescript
export type TPaginationParams = {
  page?: number
  limit?: number
}

export type TPaginatedResult<T> = {
  data: T[]
  pagination: {
    page: number
    limit: number
    total: number
    totalPages: number
    hasNext: boolean
    hasPrev: boolean
  }
}

/**
 * Get transactions for account (with pagination)
 */
export async function getTransactions(
  accountId: string,
  filters?: TTransactionFilters,
  pagination: TPaginationParams = {}
): Promise<TApiResponse<TPaginatedResult<TTransaction>>> {
  try {
    const supabase = await createClient()

    if (!(await hasAccessToAccount(accountId))) {
      return { data: null, error: 'Acesso negado', success: false }
    }

    const page = pagination.page || 1
    const limit = Math.min(pagination.limit || 50, 100) // Max 100
    const from = (page - 1) * limit
    const to = from + limit - 1

    // Build query
    let query = supabase
      .from('transactions')
      .select('*', { count: 'exact' })
      .eq('account_id', accountId)

    // Apply filters
    if (filters?.startDate) query = query.gte('date', filters.startDate)
    if (filters?.endDate) query = query.lte('date', filters.endDate)
    if (filters?.category) query = query.eq('category', filters.category)
    if (filters?.search) query = query.ilike('description', `%${filters.search}%`)
    if (filters?.minAmount) query = query.gte('amount', filters.minAmount)
    if (filters?.maxAmount) query = query.lte('amount', filters.maxAmount)

    // Order and paginate
    query = query.order('date', { ascending: false }).range(from, to)

    const { data, error, count } = await query

    if (error) {
      return { data: null, error: error.message, success: false }
    }

    const total = count || 0
    const totalPages = Math.ceil(total / limit)

    return {
      data: {
        data: data || [],
        pagination: {
          page,
          limit,
          total,
          totalPages,
          hasNext: page < totalPages,
          hasPrev: page > 1,
        },
      },
      error: null,
      success: true,
    }
  } catch (error) {
    return {
      data: null,
      error: error instanceof Error ? error.message : 'Erro ao buscar transa√ß√µes',
      success: false,
    }
  }
}
```

**Atualizar componente:**

```typescript
// src/app/(dashboard)/transactions/page.tsx
const [page, setPage] = useState(1)
const result = await getTransactions(accountId, filters, { page, limit: 20 })

// Adicionar bot√µes de pagina√ß√£o
```

**Impacto:**
- üöÄ Performance +80%
- üíæ Mem√≥ria -70%
- üì± Melhor UX mobile

**Tempo:** 3-4 horas

---

### 8. Cache para PDFs Processados

**Problema:** Re-processamento de PDFs id√™nticos desperdi√ßa recursos

**Arquivo:** Criar `src/lib/pdf/cache.ts`

**Solu√ß√£o:**

```typescript
import crypto from 'crypto'

interface CacheEntry {
  hash: string
  result: TPdfParseResult
  timestamp: number
}

// Simple in-memory cache (para produ√ß√£o, usar Redis)
const cache = new Map<string, CacheEntry>()
const CACHE_TTL = 24 * 60 * 60 * 1000 // 24 horas

/**
 * Generate hash from file buffer
 */
export function generateFileHash(buffer: ArrayBuffer): string {
  const hashSum = crypto.createHash('sha256')
  hashSum.update(Buffer.from(buffer))
  return hashSum.digest('hex')
}

/**
 * Get cached parse result
 */
export function getCachedResult(hash: string): TPdfParseResult | null {
  const entry = cache.get(hash)

  if (!entry) return null

  // Check if expired
  if (Date.now() - entry.timestamp > CACHE_TTL) {
    cache.delete(hash)
    return null
  }

  return entry.result
}

/**
 * Cache parse result
 */
export function cacheResult(hash: string, result: TPdfParseResult): void {
  cache.set(hash, {
    hash,
    result,
    timestamp: Date.now(),
  })

  // Limit cache size (evict oldest)
  if (cache.size > 100) {
    const oldest = Array.from(cache.entries())
      .sort((a, b) => a[1].timestamp - b[1].timestamp)[0]
    cache.delete(oldest[0])
  }
}
```

**Usar em:** `src/lib/pdf/parser.ts`

```typescript
import { generateFileHash, getCachedResult, cacheResult } from './cache'

export async function parsePdfFile(
  file: ArrayBuffer,
  options: { debug?: boolean; useAI?: boolean; fallbackToRegex?: boolean } = {}
): Promise<TPdfParseResult> {
  const { debug = false, useAI = true, fallbackToRegex = true } = options

  // Check cache first
  const hash = generateFileHash(file)
  const cached = getCachedResult(hash)

  if (cached) {
    logger.info('PDF parse result retrieved from cache', { hash })
    return cached
  }

  try {
    // ... parse logic

    // Cache result
    const result = { transactions, period, cardLastDigits, totalAmount }
    cacheResult(hash, result)

    return result
  } catch (error) {
    // ...
  }
}
```

**Impacto:**
- üí∞ Economia OpenAI
- ‚ö° Upload instant√¢neo (cache hit)
- üåç Melhor UX

**Tempo:** 2-3 horas

---

## üìà P2 - M√©dio Prazo (1 semana)

### 9. Sistema de Categorias Personaliz√°vel

**Problema:** Categorias hardcoded, usu√°rios n√£o podem customizar

**Solu√ß√£o:**

1. **Migration SQL:**

```sql
-- db/migrations/002_custom_categories.sql

-- Add user_id to categories (optional for global categories)
ALTER TABLE categories ADD COLUMN user_id uuid REFERENCES auth.users(id);
ALTER TABLE categories ADD COLUMN account_id uuid REFERENCES accounts(id);

-- Create default categories for new users
CREATE OR REPLACE FUNCTION create_default_categories()
RETURNS TRIGGER AS $$
BEGIN
  INSERT INTO categories (name, icon, color, keywords, user_id)
  VALUES
    ('Alimenta√ß√£o', 'üçî', '#ef4444', ARRAY['restaurante', 'mercado', 'ifood'], NEW.id),
    ('Transporte', 'üöó', '#3b82f6', ARRAY['uber', 'combust√≠vel', 'taxi'], NEW.id),
    ('Sa√∫de', '‚öïÔ∏è', '#10b981', ARRAY['farm√°cia', 'm√©dico', 'hospital'], NEW.id);
  -- ... outras categorias
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER on_user_created
  AFTER INSERT ON auth.users
  FOR EACH ROW
  EXECUTE FUNCTION create_default_categories();
```

2. **Server Actions:**

```typescript
// src/actions/category.actions.ts
'use server'

export async function getUserCategories(userId: string): Promise<TApiResponse<TCategory[]>> {
  // ...
}

export async function createCategory(data: {
  name: string
  icon?: string
  color?: string
  keywords?: string[]
}): Promise<TApiResponse<TCategory>> {
  // ...
}

export async function updateCategory(
  categoryId: string,
  data: Partial<TCategory>
): Promise<TApiResponse<TCategory>> {
  // ...
}
```

3. **UI para gerenciar categorias**

**Impacto:**
- üé® Customiza√ß√£o por usu√°rio
- üß† IA aprende com padr√µes
- üìä Melhor categoriza√ß√£o

**Tempo:** 1 dia

---

### 10. Processamento Ass√≠ncrono (Queues)

**Problema:** Upload de PDF bloqueia request, timeout em PDFs grandes

**Solu√ß√£o:**

```typescript
// src/lib/queue/invoice-processor.ts
import { Queue, Worker } from 'bullmq'
import { Redis } from 'ioredis'

const connection = new Redis(process.env.REDIS_URL!)

export const invoiceQueue = new Queue('invoice-processing', { connection })

export async function enqueueInvoiceProcessing(data: {
  invoiceId: string
  fileUrl: string
  accountId: string
}) {
  await invoiceQueue.add('process-invoice', data, {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000,
    },
  })
}

// Worker
const worker = new Worker(
  'invoice-processing',
  async (job) => {
    const { invoiceId, fileUrl, accountId } = job.data

    // Download PDF
    // Parse PDF
    // Save transactions
    // Update invoice status
  },
  { connection }
)
```

**Atualizar upload:**

```typescript
// Upload apenas enfileira
const invoice = await createInvoice({ status: 'processing' })
await enqueueInvoiceProcessing({ invoiceId: invoice.id, ... })

return { data: { invoice, status: 'processing' }, ... }
```

**Impacto:**
- ‚ö° Response instant√¢neo
- üîÑ Retry autom√°tico
- üìä Monitoramento

**Tempo:** 2 dias

---

### 11. Testes Automatizados

**Estrutura:**

```bash
npm install -D vitest @testing-library/react @testing-library/jest-dom @playwright/test
```

**Configura√ß√£o:**

```typescript
// vitest.config.ts
import { defineConfig } from 'vitest/config'
import react from '@vitejs/plugin-react'
import path from 'path'

export default defineConfig({
  plugins: [react()],
  test: {
    environment: 'jsdom',
    globals: true,
    setupFiles: './vitest.setup.ts',
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
})
```

**Exemplos de testes:**

```typescript
// src/lib/analytics/__tests__/stats.test.ts
import { describe, it, expect } from 'vitest'
import { calculateTransactionStats } from '../stats'

describe('calculateTransactionStats', () => {
  it('should calculate total spent correctly', () => {
    const transactions = [
      { amount: 100, category: 'Food', date: '2025-01-01' },
      { amount: 50, category: 'Transport', date: '2025-01-02' },
    ]

    const result = calculateTransactionStats(transactions)
    expect(result.totalSpent).toBe(150)
    expect(result.averageTransaction).toBe(75)
  })
})

// src/actions/__tests__/transaction.actions.test.ts
import { describe, it, expect, vi } from 'vitest'
import { getTransactions } from '../transaction.actions'

vi.mock('@/lib/supabase/server', () => ({
  hasAccessToAccount: vi.fn(() => Promise.resolve(true)),
  createClient: vi.fn(() => ({
    from: vi.fn(() => ({
      select: vi.fn(() => ({
        eq: vi.fn(() => ({
          order: vi.fn(() => ({
            range: vi.fn(() => Promise.resolve({ data: [], count: 0 }))
          }))
        }))
      }))
    }))
  }))
}))

describe('getTransactions', () => {
  it('should return paginated results', async () => {
    const result = await getTransactions('account-id', {}, { page: 1, limit: 20 })
    expect(result.success).toBe(true)
    expect(result.data?.pagination.page).toBe(1)
  })
})
```

**E2E com Playwright:**

```typescript
// e2e/invoice-upload.spec.ts
import { test, expect } from '@playwright/test'

test('should upload invoice and extract transactions', async ({ page }) => {
  await page.goto('/login')
  await page.fill('[name="email"]', 'test@example.com')
  await page.fill('[name="password"]', 'password123')
  await page.click('button[type="submit"]')

  await page.goto('/invoices')
  await page.setInputFiles('input[type="file"]', './fixtures/invoice.pdf')

  await expect(page.locator('text=Upload conclu√≠do')).toBeVisible()
})
```

**Impacto:**
- üêõ Menos bugs em produ√ß√£o
- üîÑ Refatora√ß√£o segura
- üìä Cobertura de c√≥digo

**Tempo:** 3 dias

---

### 12. Monitoramento e Analytics

**Sentry para Error Tracking:**

```typescript
// src/lib/sentry.ts
import * as Sentry from '@sentry/nextjs'

Sentry.init({
  dsn: process.env.NEXT_PUBLIC_SENTRY_DSN,
  environment: process.env.NODE_ENV,
  tracesSampleRate: 1.0,
  beforeSend(event) {
    // Filter sensitive data
    if (event.request?.cookies) {
      delete event.request.cookies
    }
    return event
  },
})

export { Sentry }
```

**Analytics:**

```typescript
// src/lib/analytics.ts
export const trackEvent = (eventName: string, properties?: Record<string, any>) => {
  if (typeof window !== 'undefined') {
    // Google Analytics
    window.gtag?.('event', eventName, properties)

    // Posthog
    window.posthog?.capture(eventName, properties)
  }
}

// Usage
trackEvent('invoice_uploaded', { accountId, fileSize, parseMethod: 'AI' })
trackEvent('transaction_edited', { category, amount })
```

**Cost Tracking OpenAI:**

```typescript
// src/lib/analytics/cost-tracking.ts
export async function trackOpenAICost(usage: {
  promptTokens: number
  completionTokens: number
  model: string
}) {
  const costs = {
    'gpt-4o-mini': { input: 0.15, output: 0.60 }, // per 1M tokens
  }

  const cost = costs[usage.model]
  const inputCost = (usage.promptTokens / 1_000_000) * cost.input
  const outputCost = (usage.completionTokens / 1_000_000) * cost.output
  const totalCost = inputCost + outputCost

  // Save to database
  await supabase.from('ai_usage_logs').insert({
    model: usage.model,
    prompt_tokens: usage.promptTokens,
    completion_tokens: usage.completionTokens,
    cost_usd: totalCost,
  })

  logger.info('OpenAI usage tracked', { usage, totalCost })
}
```

**Impacto:**
- üö® Alertas proativos
- üìä Insights de uso
- üí∞ Controle de custos

**Tempo:** 2 dias

---

## üîí P3 - Seguran√ßa (2 semanas)

### 13. CSRF Protection

```typescript
// src/middleware.ts
import { csrf } from '@/lib/csrf'

export async function middleware(request: NextRequest) {
  // CSRF check for POST/PUT/DELETE
  if (['POST', 'PUT', 'DELETE'].includes(request.method)) {
    const valid = await csrf.verify(request)
    if (!valid) {
      return new Response('CSRF validation failed', { status: 403 })
    }
  }

  return await updateSession(request)
}
```

**Tempo:** 1 dia

---

### 14. Input Sanitization

```typescript
// src/lib/sanitize.ts
import DOMPurify from 'isomorphic-dompurify'

export function sanitizeHtml(dirty: string): string {
  return DOMPurify.sanitize(dirty, { ALLOWED_TAGS: [] })
}

export function sanitizeFileName(fileName: string): string {
  return fileName
    .replace(/[^a-zA-Z0-9._-]/g, '')
    .substring(0, 255)
}
```

**Tempo:** 4 horas

---

## üéÅ P4 - Nice to Have (1-2 semanas)

### 15. Webhooks para Notifica√ß√µes

```typescript
// src/lib/webhooks/discord.ts
export async function notifyInvoiceProcessed(invoice: TInvoice) {
  if (!process.env.DISCORD_WEBHOOK_URL) return

  await fetch(process.env.DISCORD_WEBHOOK_URL, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      content: `‚úÖ Fatura processada: ${invoice.period} - R$ ${invoice.total_amount}`,
    }),
  })
}
```

**Tempo:** 3 dias

---

## üìã Checklist de Implementa√ß√£o

### Semana 1 - P0 + P1
- [ ] Valida√ß√£o de env vars
- [ ] Rate limiting uploads
- [ ] Logging estruturado
- [ ] Helpers de valida√ß√£o
- [ ] Otimiza√ß√£o N+1 queries
- [ ] Centraliza√ß√£o de stats
- [ ] Pagina√ß√£o
- [ ] Cache PDF

### Semana 2 - P2
- [ ] Categorias customiz√°veis
- [ ] Queue para processamento
- [ ] Testes unit√°rios
- [ ] Testes E2E

### Semana 3 - P2 + P3
- [ ] Sentry + Analytics
- [ ] Cost tracking
- [ ] CSRF protection
- [ ] Input sanitization

### Semana 4 - P3 + P4
- [ ] Auditoria de seguran√ßa
- [ ] Webhooks
- [ ] Documenta√ß√£o final
- [ ] Deploy otimizado

---

## üéØ M√©tricas de Sucesso

| M√©trica | Antes | Meta | Melhoria |
|---------|-------|------|----------|
| Tempo de upload | 15s | 2s | +85% |
| Queries por request | 10+ | 2-3 | +70% |
| Cobertura de testes | 0% | 70% | +70% |
| Bugs em produ√ß√£o | 5/m√™s | <1/m√™s | +80% |
| Custo OpenAI | $100/m√™s | $60/m√™s | +40% |

---

## üìù Notas de Implementa√ß√£o

1. **Priorize P0** - Seguran√ßa e performance primeiro
2. **Teste incrementalmente** - N√£o refatore tudo de uma vez
3. **Documente mudan√ßas** - Atualize README e CLAUDE.md
4. **Monitore impacto** - Valide melhorias com m√©tricas
5. **Pe√ßa feedback** - Teste com usu√°rios reais

---

## üöÄ Pr√≥ximos Passos

1. Revisar este plano com a equipe
2. Priorizar itens com base no roadmap
3. Criar issues/tasks no GitHub
4. Implementar P0 primeiro (cr√≠tico)
5. Iterar semanalmente

---

**Documento criado em:** 2025-10-24
**√öltima atualiza√ß√£o:** 2025-10-24
**Vers√£o:** 1.0
